\begin{abstract}
Streaming of live video contents to the targeted audiences has become popular with advances of online social streaming applications over smartphones such as YouTube live, Instagram, Periscope, Twitch.tv, Meerkat, etc. For many of such applications, typically, majority of the end-users or viewers are either from the same locality or form a cluster of localities. For example, a video where the director of an organization is giving a talk in a conference, majority of the viewers will be typically from the different offices of that organization. In this paper, we leverage this idea and develop an edge-assisted adaptive live streaming framework where the viewers who are close to each other and are under the same networking environment form a set of streaming coalitions; the members of a streaming coalition collectively download the content and stream to each other using adaptive streaming. Such an approach reduces the total amount of data directly downloaded from the content server, and hence, reduces the Internet cost, brings down the streaming delay and improves the overall quality of experience (QoE) for the end-users. To facilitate the adaptive streaming over a dynamic coalition based on the network environment, we adopt a deep reinforcement learning framework to decide the quality of the video chunks to be downloaded and the download responsibilities for each member in the coalition. The proposed framework has been implemented and tested in an realistic emulation environment, and a significant performance boost in the live streaming quality has been observed, in comparison with various other baseline approaches.
\end{abstract}