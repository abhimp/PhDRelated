\section{Introduction}\label{sec:chap05:intro}
Video traffic over the Internet has increased many-fold in recent years with the growing popularity of various over-the-top (OTT) media services like NetFlix, HotStar, Hulu, Amazon Prime, etc., over the world. The OTT service providers take help of the content delivery networks (CDN) to host the video contents and use HTTP Adaptive Streaming (HAS)~\cite{}, mostly powered by Apple HLS~\cite{} and MPEG-DASH~\cite{}, at the core of the streaming mechanism. HAS helps the end-users to meet the quality of experience (QoE) for the video streaming based on the variability at the network bandwidth available to the streaming players for downloading the video contents. More specifically, the HAS algorithms measure the available bandwidth at the clients and requests for the video segments in one of the predefined quality levels (bitrates) such that the QoE objectives for the end-user can be ensured. Typically, the QoE for the end-users of OTT services is characterized through following four metrics~\cite{} -- (i) video start-up delay, (ii) average playback bitrate, (iii) bitrate variation during the video playback, and (iv) amount of rebuffering or playback-stalls. Indicatively, the end-users demand for high bitrate video streaming with zero rebuffering to have the best video playing experience, while having some importance on the start-up dely and the bitrate variation. 

Mobile OTT applications have seen a tremendous demand in the recent years, however, supporting interrupt-free high-bitrate video streaming over wireless environments, both with WiFi and cellular technologies, is a daunting challenge for the OTT service providers because of the high variability of the air-interfaces' throughput, both with WiFi and cellular technologies. Traditional buffer-based HAS techniques~\cite{} fail in such scenarios, as they make an estimate of the network condition by observing the average playback buffer occupancy at the streaming client. However, the average buffer length at the playback client does not provide the short-term efficacy of the wireless channel. For example, an instantaneous drop in the throughput due to an external interference in the wireless channel cannot be captured by measuring the average buffer length. However, such instantaneous variations can trigger a rebuffering, thus affecting the QoE of the end-users.  

To mitigate these problems, various recent literature~\cite{} have proposed machine learning (ML)-based toolboxes to decide the video bitrates depending on a number of parameters that might influence the network conditions. However, these approaches have two major limitations. (1) The bitrate selection algorithms used in HAS typically run at the client side. Running ML-based algorithms over handheld devices always have their cost implications in terms of resource consumption and energy-efficiency~\cite{}. Apart from the runtime costs, the pretrained model needs to be pushed at the client devices periodically, which also incur additional overhead. It can be noted that a server-support to run the ML model is not practically feasible, as the bitrate decision is taken for every video segments to be downloaded. Considering the typical segment length of HAS videos are in the range of a few seconds, the client needs very frequent server access, which can affect its performance. (2) Typically, the ML algorithms are sophisticated enough to get pretrained over a number of variable input parameters. However, if they are executed only based on the clients' local states, they may not be able to capture the accurate condition of the network~\cite{}. For example, existing studies~\cite{} show that a contention among multiple video streams from different clients, connected with the same WiFi access point (AP), results in unfair air-time distribution across the clients, resulting in poor QoE. The information about the number of clients currently sharing the total air-time is only available at the AP side, and not at the client side. Thus, only the client-side parameters may not make the model sophisticated anough to capture wireless channel variability. 

In this paper, we first perform a thorough study to show that the existing ML-based HAS mechanisms, like MPC~\cite{} and Pensieve~\cite{}, fail to correctly capture the wireless channel throughput when only the client states are used in the prediction model. Accordingly, in this paper, we propose an edge-assisted HAS mechanism for dynamic bitrate adaptation, called {\bel}, primarily targeting the wireless interfaces. In our approach, we take help of the last-mile access device, such as the WiFi AP, to decide the optimal bitrate for video streaming with an objective of maximizing the end-users' QoE. In {\bel}, we use a middlebox server, called {\servname}, that works as a proxy to run the bitrate selection algorithm on behalf of the clients associated with it, and then forwards the video download requests to the CDN server. However, such an architecture poses additional design challenges. Mobile clients trigger handovers from one \textit{point of association} (PoA), like the WiFi AP or cellular base stations, to the next. Therefore, the HAS client states preserved at {\servname} also need to be transferred from the current PoA to the next PoA. As this again posses additional overhead, ideally, we need a stateless mechanism for bitrate selection. In {\bel}, we develop a semi-stateful model for bitrate selection, such that the client handover incurs minimal cost in terms of state exchange between different {\servname} components. 

To further address the efficacy of {\bel} over existing HAS models, we developed a proof of concept (PoC) bitrate selection mechanism for the clients attached with a WIFi AP. We developed a ML model for bitrate selection based on the wireless channel states and connection-level parameters measured at the WiFi AP. It can be noted that one of the major advantages of {\bel} architecture is that it is client-agnostic. The client software does not need any modification depending on whether the device gets connected over a WiFi network or a cellular network. We only need the corresponding pretrained model to be pushed at {\servname} associated with the WiFi AP or the cellular base station.   

\notesc{Implementation and results ...}

In summary, our contributions in this paper are as follows. 
\begin{enumerate}
    \item From thorough analysis of WiFi channel states and its impact over the WiFi clients during video streaming, we show that the existing HAS bitrate selection models does not perform efficiently when only the client states are used for the optimal bitrate prediction. 
    \item We design and develop {\bel}, a middlebox at the edge, for optimal bitrate selection based on joint coordination between the client and its wireless PoA. 
    \item To reduce the overhead of {\bel}, we propose a semi-stateful model. \notesc{need to give further details about the novelty}. 
    \item We develop a PoC for ML-based bitrate selection using {\bel} over WiFi networks. \notesc{further details in terms of novelty} 
    \item \notesc{Contributions regarding implementation}
\end{enumerate}

\notesc{===TODOs=======}

\notesc{1. Over a WiFi setup, show that PenSieve and MPC fails to capture the correct bitrate based on only the states of the client. This can be a case study. Like play BBB from 10 clients associated with a AP, and show how WiFi channel variations impact bitrate selection. You may also show that the imput parameters of PenSieve does not correctly capture the wireless channel states.}

\notesc{2. Be careful about writing the methodology, use different figures, different terminologies, etc. from the patent document shared with Intel. Do not try to modify the architecture proposed in the patent -- write here from scratch.}

\notesc{3. Implement and test with WiFi networks. We need to develop a training model using the WiFi AP states, think about which parameters you'll take from AP. We need to show that this model works better than PenSieve and others.}

\notesc{4. Detailed analysis and results from implementation -- (a) emulation/simulation, (b) small-scale testbed. Brainstorm what graphs we want to give. Accordingly you can run the experiments to generate graphs.}

\vspace{1cm}
\notesc{\Large{\textbf{== Old Intro ===}}}


To improve the performance of \ac{DASH}, which is the primary video rendering protocol in recent times,  several \ac{ABR} video streaming algorithms have been proposed. Some of these algorithms, such as Pensieve \cite{mao2017neural}, use \ac{ML} to decide the most optimal bitrates for video download. However, a deep rooted concern associated with the unbridled use of \ac{ML} algorithms in such applications as video streaming is the feasibility in their deployment. Particularly, in many emerging countries like India, a major section of the society uses medium budget smartphones with limited specifications. These phones may not, therefore, be capable of handling the requirements associated with running an \ac{ML}-equipped \ac{ABR} streaming algorithm.\\
\indent For example, for each video played by the client, Pensieve \cite{mao2017neural} needs a trained model to decide the optimal download bitrate for the next video segment. This implies that  a different trained model should be stored for each video, which escalates the storage requirement. The alternative is online retraining of the algorithms, which again needs a huge amount of computational resources for delivering timely and accurate results. As DASH uses a dumb server and a smart client, both of the aforementioned solutions are to be implemented in the smartphones, i.e., where the client video player resides.  If the phones, however, have low memory and insufficient computational resources then \ac{ML}-assisted \ac{ABR} algorithms can trigger scalability issues.\\
\indent Algorithms like Pensieve \cite{mao2017neural}, Oboe \cite{Akhtar2018}, HotDASH \cite{Sengupta2018} require an  ABR server which hosts and runs these algorithms. To minimize the time taken in information exchanges between the \ac{ABR} server and the client, \cite{mao2017neural,Akhtar2018,Sengupta2018} propose that the \ac{ABR} server be located at the client itself. This implies that a local server be run at the end-devices, i.e., the smartphones, one for each player, which further leads to scalability concerns.\\
% chooses the download bitrate of the current video chunk as a function of the last chunk bitrate and some other parameters. However, in cellular networks, the chunk bitrate depends on the channel throughput. In such cases, the channel coherence time i.e., the time over which the channel response remains unchanged may be significantly smaller than the inter video segment download time.  For example, in 5G the channel coherence time is in the order of miliseconds ~\cite{}, whereas the time between two successive video segment download is in the order of seconds. Consequently, choosing the current chunk bitrate as a function of that of the last chunk may lead to erroneous decisions.
% \indent To ensure convenient deployment of \ac{ML} algorithms for optimal video streaming, in this paper, we have proposed a modification to the \ac{DASH} architecture while not altering the fundamental philosophy of \ac{DASH}. \\
\indent \ac{DASH} provides a low-complexity common ecosystem of networks and services obliterating the proprietary content silos. However, it solicits some modification for exploiting the benefits offered by \ac{ML}-assisted \ac{ABR} streaming algorithms, particularly for supporting such algorithms in medium and low budget phones. However, the ubiquitous usage of \ac{DASH} implies that any  modification must not alter the fundamental philosophy of \ac{DASH}, wherein the control lies with the client which takes the decisions for selecting the optimal next chunk download bitrates for individual users. \\
% \indent In the conventional \ac{DASH} architecture a target video is first encoded and then fragmented into chunks of fixed playback time. These chunks are stored at a \ac{CDN} server. The encoding ensures that the video player can distinguish between each chunk separately. There is a video player at the client side. The client takes stock of the current network bandwidth and the playback buffer of the video player. The \ac{ABR} streaming algorithm at the client side uses a combination of one or more of these metrics to decide the download bitrate of the next video chunk. So, in conventional DASH  the server is relieved of any additional workload associated with the choosing the optimal next chunk download bitrate for individual users. The entire control lies with the client side. \\
    \indent Our proposed modification, named \bel\ \footnote{Belovezha Accords is an agreement declaring the cessation of existence of USSR and hence the splitting of the same.}, splits the \ac{DASH} decision making engine. It replaces the smart client with a dumb client and introduces a middlebox in the form of an intelligent proxy server between the \ac{CDN} server and the client. We call the intelligent server \servname\footnote{\servname\ is the bridge connecting Asgard, the world of Gods, to Midgard, the world of humanity.}. \servname\ may be co-located either with a \ac{CDN} server  or the cellular network base-station. In either case the introduction of \servname\ does not disturb the organization of the host. \servname\ houses the \ac{ABR} server of~\cite{mao2017neural,Akhtar2018,Sengupta2018} and is equipped with advanced technical parts for training the \ac{ABR} algorithms inside the \ac{ABR} server.  Thus, \bel\ offers the advantage of incorporating \ac{ML}-based \ac{ABR} streaming algorithms with DASH, without overwhelming the client. In fact, splitting the \ac{ABR} decision making engine from the client implies that the client requires no (a) add-on installation (\ac{ML} algorithms often have library dependencies that may not be well-defined for smartphones) , or (b) high-end features. Although targeted towards smooth incorporation of machine learning in \ac{DASH} \bel\ is expected to perform equally well non-\ac{ML} equipped \ac{ABR} algorithms.\\
    \indent In this work, we have implemented  the \bel\ client as an android application using HTML5 and Javascript. The \bel\ moderator-server - \servname\ has been developed in Python as an HTTP server with several special features. This bypasses the need to restructure the existing \ac{ML}-based ABR algorithms for training in smartphones, thereby extending the service to phones with limited features. Moreover, since a much higher number of cores can be made available in the server than the smartphone, hence, accurate bitrate decisions can be delivered in much less time. Our experimental results reflect that \bel\ performs at par with the unified \ac{DASH} architecture for ML-based ABR algorithms as well as other algorithms.  \\
    \indent It is, thus, evident that \servname\ is a middlebox. Although middleboxes introduce new functionalities, they often become bottlenecks due to proprietary control or increase in information exchange. So, several existing works \cite{Sherry2012} argue in the favour of doing away with middleboxes altogether. However, we have designed \servname\ simply as a plugin module. It does not have any proprietary control. Besides, our experiments show that there is no significant increase in the control channel overhead associated with \servname. It can, therefore, be used as a simple solution for improving user experience.

% In recent times, there has been an increase in the popularity of machine learning algorithms for the selection of optimal bit rates in \ac{DASH} 
% %stimulated by availability of low cost smartphones, affordable data plans, and a variety of  content on OTT video platforms,
% online video streaming has emerged as one of the most popular modes of entertainment. Most video users stream online videos in their smartphones over the mobile Internet. Hence, a stable mobile connection quality is integral to a satisfactory video viewing experience. However, the mobile connection quality is susceptible to random fluctuations, especially for travellers. A user under mobility in one instance may experience a 4G connection quality, in the next instance it may have to fallback to legacy 3G or 2G networks, or may have to pass through a connection blind spot with no reception at all. Such fluctuations introduce interruptions in the video playback, which reflect into a poor \ac{QoE} for the user. Provisioning a high \ac{QoE} to video users in the face of the fluctuating network conditions is one of the principal challenges encountered by network engineers and service providers.\\
% \indent Currently, video service providers serve video content using the \ac{DASH} protocol. In \ac{DASH}, a target video is stored at a \ac{CDN} server  after first being encoded in different qualities and then broken into chunks of equal playback times. The encoding ensures that the video player can understand each video chunk independently. A DASH video player, usually the client at the user end, estimates the current network bandwidth as well as the playback conditions and then employs an \ac{ABR} video streaming algorithm to determine the quality of the next video chunk to be fetched.\\
% \indent An incorrect estimate of the bit-rate may significantly deteriorate the \ac{QoE} of the user. For example, a high bit-rate estimate in the face of poor network conditions can increase the rebuffering time. Additionally, incessant bitrate variations (or less smoothness) between adjacent chunks or streaming at a lower bitrate also affects the \ac{QoE}. To this end, \ac{ABR} streaming algorithms optimizes the bitrate selection over three conflicting objectives - (a) high bitrate, (b) less rebuffering time, and (c) high smoothness. Popular \ac{ABR} algorithms such as MPC \cite{yin2015control}, BOLA \cite{Spiteri2016}, Pensieve \cite{mao2017neural}

% \noteng{The exact problem statement is introduced a bit late, Consider coming to the point may be after the first three paragraph. In general written well. }