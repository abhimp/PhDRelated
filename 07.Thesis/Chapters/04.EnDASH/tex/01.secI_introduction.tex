%\section{\textbf{Introduction}}
\label{sec:chap04:intro}


%With the pervasive roll out of the \ac{4G} cellular networks, online video streaming in smartphones has become one of the most popular modes of entertainment~\cite{CISCO2019}, especially in many developing countries. The availability of ultra cheap data plans, affordable smartphones, and local language based content on YouTube, Netflix, etc., has led to a record increase in the number of mobile video subscribers as well as their engagement time~\cite{Mobstat_2019}.  Subscribers have  shown an inclination towards watching streaming videos even while travelling, irrespective of the distances travelled. Provisioning the expected \ac{QoE} to video users during travelling requires the reception of a stable connection quality at the \acp{UE}, which often eludes users in developing nations. This is because in these countries service providers often compromise on the network infrastructure to provide low cost internet~\cite{Poor_Inf_2019_2}. \\
%\indent Another non-negligible impact of mobility on video streaming in  smartphones is the drainage of battery power.  Video streaming itself is a power hungry application~\cite{Xin2012}. Our experiments show that under mobility, video streaming apps consume even more power (\S\ref{sec:chap03:DASHinMobility}). The reason for this can be attributed to the fluctuating connection quality experienced while travelling.  This chapter proposes to improve the smartphone battery usage through the design of an energy efficient video streaming algorithm that leverages the fluctuating cellular network throughput to choose optimal bitrates while not compromising on the required \ac{QoE}s. \\
%\indent 
%
%
%\indent Video streaming applications, including live streaming, predominantly use \ac{DASH} \cite{stockhammer2011dynamic}. In this protocol, the target video is broken into chunks of fixed playback time, and multiple copies of each chunk is stored  at different quality levels, i.e., bitrates.  The client side video player uses \ac{ABR} algorithms~\cite{mao2017neural,Spiteri2016,yin2015control,Raca2019,Akhtar2018}
%to decide on the  bitrate at which the next chunk is to be fetched. Existing \ac{DASH} algorithms  primarily take bitrate decisions based on the estimated network throughput or the playback buffer size while attempting to improve user's \ac{QoE}. We, on the other hand, hypothesize that it is possible to significantly lower the energy usage without sacrificing \ac{QoE} if we intelligently utilize the nuances of the cellular network throughput fluctuation during ABR streaming.
With the pervasive roll out of the \ac{4G} cellular networks, online video streaming in smartphones has become one of the most popular modes of entertainment~\cite{CISCO2019}, especially in many developing countries. The availability of ultra cheap data plans, affordable smartphones, and local
language based content on YouTube, Netflix, etc., has led to a record increase in the number of mobile video subscribers as well as their engagement time~\cite{Mobstat_2019}. Subscribers have shown an inclination towards watching streaming videos even while traveling, irrespective of the distances traveled. Provisioning the expected \ac{QoE} to video users during traveling requires the reception of a stable connection quality at the \acp{UE}, which often eludes users in developing nations. This is because in these countries service providers often compromise on the network infrastructure to provide low cost Internet~\cite{Poor_Inf_2019_2}. 

Another non-negligible impact of mobility on video streaming in smartphones is the drainage of battery power. Video streaming itself is a power hungry application. In the previous chapter, we have seen that the cellular network is not uniform over a region, and a \ac{UE} may need to perform handover (both vertical and horizontal) several time to stay connected. We also observed that there are several radio related parameter which indirectly affect the throughput and energy consumption over the time. Such variability in the wireless channel conditions not only affect the \ac{QoE} during video streaming, but also impact the energy consumption of the device that runs the video streaming client. 

\ac{4G}-\ac{LTE} smartphones are designed to maintain network connectivity using a \ac{RRC} state machine with two states: CONNECTED and IDLE. With
no active transmission, the \ac{UE} is in the low power IDLE state where no radio resource is assigned. Once a packet arrives, the \ac{UE} jumps to the high power CONNECTED state, in which radio resources are assigned and data transmission
takes place. To reduce the incumbent delay and energy consumption associated with the state promotion, once the packet transmission is over the \ac{UE} waits for a duration called tail time in the CONNECTED state before returning to the IDLE state. To save energy in the tail period, \ac{LTE} uses \ac{DRX} during which the cellular interface periodically monitors the control channel for incoming packets and then goes to sleep. Evidently, if video is downloaded during poor connection quality, then the smartphone will have a longer CONNECTED state dwell time resulting in higher energy consumption. Existing \ac{ABR} video streaming algorithms, however, primarily focus on improving \ac{QoE} while paying little attention to energy savings.

To this end, we build an energy efficient video player, called {\bf EnDASH}, as a wrapper over \ac{DASH}. EnDASH predicts the average cellular network throughput over a finite future time window to take decisions on the opportune fetching of video chunks by dynamically increasing the playback buffer size. So, it (i) predicts the the cellular network link throughput from radio related parameters, (ii) then uses the predicted throughput to predict the playback buffer length, and (iii) finally uses the predicted buffer length to choose optimal bitrates for future chunks. Thus, EnDASH consists of three prediction modules, of which the throughput prediction uses random forest learning (step (i)). However, EnDASH works over a smartphone connected to a cellular network which is a randomly varying environment. So, it uses Deep Reinforcement Learning (RL) for the buffer-length prediction mechanism (step (ii)) and bitrate adaptation (step (iii)), which allows EnDASH to exploit the actual performance of previous choices to tune its operation to the current characteristic of the network.  Consequently, EnDASH can start without any apriori knowledge and gradually learn through exploration and exploitation.  The playback buffer length and bitrate decision engines use Deep Neural Networks to map `raw' observations to outputs. These two engines operate using $A3C$~\cite{mao2017neural}, a state-of-the-art actor-critic RL algorithm, and run asynchronously with respect to one another. We train individual prediction modules over a large corpus of collected data traces and evaluate EnDASH using an emulation environment. In this chapter, we give the detailed design of the EnDASH system along with its implementation and performance analysis. 

The rest of the chapters is organized as follows. 


%\indent Evaluation using our emulation platform shows that in comparison to existing \ac{ABR} algorithms~\cite{mao2017neural,Spiteri2016,yin2015control}, EnDASH significantly improves the energy savings in smartphones (\S\ref{sec:chap04:evaluation}). Energy saved from playing a $2200$ second video using EnDASH can be used to gain an additional $1440$ seconds of video playback time in comparison to the popular Pensieve algorithm~\cite{mao2017neural}. The energy savings, however, comes at the cost of marginally reduced \ac{QoE}.
%One of the most salient features of EnDASH, which sets it apart from existing \ac{ABR} algorithms~\cite{mao2017neural,Spiteri2016,Sengupta2018,yin2015control,Raca2019,Akhtar2018,Schulman2010} is that its throughput prediction engine captures the impact of not only the received signal strength but also other network related parameters, such as different technologies and vertical handovers. 
%The Mean Absolute Percentage Error (MAPE) of the throughput prediction engine of EnDASH varies from $8\%$ to $13\%$ across different scenarios. The improvement is particularly pronounced in regions having a substantial presence of legacy networks.
%The improved throughput prediction assists the EnDASH RL engine to accurately capture the playback buffer evolution, which in turn aids the video segment download in an energy-efficient but QoE favourable manner.\vspace*{-0.2cm}
