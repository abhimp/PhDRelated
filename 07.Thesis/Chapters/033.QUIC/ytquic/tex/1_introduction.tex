%\section{Introduction}
%\label{sec:introduction}
%Google proposed Quick UDP Internet Connections (QUIC) in $2013$ as an improvement over the use of TCP for HTTP connections~\cite{quic:2013:online}. QUIC uses UDP as the transport protocol underneath to improve on congestion control and provides zero round trip time (RTT) connections, thereby reduces latency in connection setup and message delivery. Although QUIC is focused on improving the page load time for browsing applications, the properties of QUIC make it an ideal candidate for investigating its use for dynamic adaptive bitrate streaming. In fact, Google uses QUIC for streaming video in YouTube.

%Benefits of QUIC for browsing have been studied in some works.
%Carlucci et al.~\cite{carlucci2015http} have shown that QUIC can reduce page load times in comparison to both HTTP and SPDY, another transport protocol developed by Google on top of TCP. 
%%A factor behind this gain is the use of UDP by QUIC.
%Megyesi et al.~\cite{quicisquic} have also performed an experimental evaluation of QUIC, HTTP and SPDY to arrive at similar benefits of QUIC for reducing page load time. This opens the curiosity whether QUIC can be a protocol of choice for latency sensitive video streaming applications.

In this section, we first aim to compare the performance of YouTube streaming over \ac{QUIC} with that of \ac{TCP}. 
%We focus on a specific video streaming application, namely YouTube, which can send its traffic over QUIC.
The goal is to quantify the advantages and disadvantages of choosing \ac{QUIC} by systematically monitoring video quality parameters, such as bitrate, number of bitrate switches, rebuffering, and data wastage, as we have seen in the previous chapter. We setup a controlled environment to capture the traffic streamed to a browser from YouTube server, and analyze it to quantify the metrics. The important contribution of this section is in objectively identifying the merits and demerits of \ac{QUIC} for streaming. 

%Using data gathered from $175$ video streams, we observe that QUIC maintains a higher bitrate on average compared to that of streaming over TCP, while incurring lower number of bitrate switches. However, QUIC suffers from higher rebuffering events, and also downloads more data than that of TCP streams.
%Thus QUIC achieves better performance at a hidden cost, which is brought out in this paper.

%The rest of the paper is organized as follows. 
%In Section ....


\begin{comment}
As we know, adaptive bitrate streaming has become the standard for delivering video content online to multiple devices. This type of delivery is a combination of server and client software that detects a client’s bandwidth capacity and adjusts the quality of the video stream between multiple bitrates and/or resolutions. The adaptive bitrate video experience is superior to delivering a static video file at a single bitrate, because the video stream can be switched midstream to be as good or bad as the client’s available network speed (as opposed to the buffering or interruption in playback that can happen when client’s network speed can’t support the quality of video). Because it uses the standard HTTP port, the lack of firewalls, special proxies or caches, and its cost efficiency have increased its popularity and use. There are three main protocols for this type of delivery- HTTP Live Streaming, Microsoft Smooth Streaming, and HTTP Dynamic Streaming. Each protocol uses different methods and formats, and therefore, to receive the content from each server, a device must support each protocol. A standard for HTTP streaming of multimedia content would allow a standard-based client to stream content from any standard-based server, thereby enabling consistent playback and unification of servers and clients of different vendors.\footnote{\url{https://www.encoding.com/mpeg-dash/} (\lastaccessedtoday)}
In response to the scattered landscape, the research community has developed the specifications for \textit{dynamic adaptive streaming over HTTP} (DASH), which has later on been standardized by DASH Industry Forum.\footnote{\url{http://dashif.org/} (\lastaccessedtoday)}

In \textbf{Chromium blog} on Friday, April 17, 2015 Google has released some performance update about QUIC. In there words :

{\em ``Results so far are positive, with the data showing that QUIC provides a real performance improvement over TCP thanks to QUIC's lower-latency connection establishment, improved congestion control, and better loss recovery.
	For latency-sensitive services like web search, the largest gains come from zero-round-trip connection establishment. The standard way to do secure web browsing involves communicating over TCP + TLS, which requires 2 to 3 round trips with a server to establish a secure connection before the browser can request the actual web page. QUIC is designed so that if a client has talked to a given server before, it can can start sending data without any round trips, which makes web pages load faster. The data shows that 75\% percent of connections can take advantage of QUIC’s zero-round-trip feature. Even on a well-optimized site like Google Search, where connections are often pre-established, we still see a 3\% improvement in mean page load time with QUIC. Another substantial gain for QUIC is improved congestion control and loss recovery. Packet sequence numbers are never reused when retransmitting a packet. This avoids ambiguity about which packets have been received and avoids dreaded retransmission timeouts. \textbf{As a result, QUIC outshines TCP under poor network conditions, shaving a full second off the Google Search page load time for the slowest 1\% of connections.   These benefits are even more apparent for video services like YouTube. Users report 30\% fewer rebuffers when watching videos over QUIC. This means less time spent staring at the spinner and more time watching videos."}}\footnote{\url{https://blog.chromium.org/2015/04/a-quic-update-on-googles-experimental.html} (\lastaccessedtoday)}


In this context we are trying to know whether QUIC has any additional advantages for YouTube like improved video quality rendered over time  besides fewer rebuffers. Is there any price that we need to pay for better video quality or there is no such trade-off? In this project we mainly compare the performance in terms of video quality rendered over time by both the protocols and check whether our hypothesis that QUIC will perform better over DASH when compared to TCP is valid or not and is there any price for it.
\end{comment}
